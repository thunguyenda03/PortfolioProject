from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
sales = pd.read_csv("/content/drive/MyDrive/Walmart.csv")

"""DATA OVERVIEW"""

sales.shape

sales.describe()

sales.dtypes

sales.head(5)

"""DATA PREPROCESSING"""

sales.isnull().sum()

dups = sales.duplicated()
print('Number of duplicate rows = %d' % (dups.sum()))

sales['Date'] = pd.to_datetime(sales['Date'],format='%d-%m-%Y')

sales['Quarter'] = sales['Date'].dt.to_period('Q').dt.quarter

sales

"""Year"""

sales['Date'] = pd.to_datetime(sales['Date'], format='%d-%m-%Y')

sales['Year'] = sales['Date'].dt.year

sales

"""Month"""

sales['Date'] = pd.to_datetime(sales['Date'], format='%d-%m-%Y')


sales['Month'] = sales['Date'].dt.month

sales

sales['Day'] = sales['Date'].dt.day
sales

"""Week of the Year"""

sales['Week_of_Year'] = sales['Date'].dt.isocalendar().week
sales

sales['Date'] = pd.to_datetime(sales['Date'], format='%d-%m-%Y')

sales['Store'] = sales['Store'].astype('object')
sales['Quarter'] = sales['Quarter'].astype('object')
sales['Year'] = sales['Year'].astype('object')
sales['Month'] = sales['Month'].astype('object')
sales['Day'] = sales['Day'].astype('object')
sales['Week_of_Year'] = sales['Week_of_Year'].astype('object')
sales['Holiday_Flag'] = sales['Holiday_Flag'].astype('object')

sales.dtypes

"""Assing Name to Holiday date

Super Bowl: 12-Feb-10, 11-Feb-11, 10-Feb-12

Labour Day: 10-Sep-10, 9-Sep-11, 7-Sep-12

Thanksgiving: 26-Nov-10, 25-Nov-11, 23-Nov-12

Christmas: 31-Dec-10, 30-Dec-11, 28-Dec-12
"""

sales['Holiday_Event'] = 'Not Holiday'

holiday_dates = {'Super Bowl':['2010-02-12', '2011-02-11', '2012-02-10'],
                 'Labor Day': ['2010-09-10', '2011-09-09', '2012-09-07'],
                 'Thanksgiving': ['2010-11-26', '2011-11-25', '2012-11-23'],
                 'Christmas': ['2010-12-31', '2011-12-30', '2012-12-28']}
for holiday, dates in holiday_dates.items():
    sales.loc[sales['Date'].isin(dates), 'Holiday_Event'] = holiday

sales

"""EXPLONATORY DATA ANALYSIS

Stores with the highest sales
"""

import matplotlib.pyplot as plt
import seaborn as sns

agg_sales = sales.groupby('Store')['Weekly_Sales'].sum().reset_index()

sorted = agg_sales.sort_values(by='Weekly_Sales', ascending=False).head(3)

plt.figure(figsize=(12, 6))
barplot = sns.barplot(data=sorted, x='Store', y='Weekly_Sales',order = sorted['Store'], palette = "Set2")
plt.title('Weekly Sales by Store')
plt.xlabel('Store')
plt.ylabel('Weekly Sales')
plt.legend(title='Store')
plt.grid(False)



y_max = sorted['Weekly_Sales'].max()
plt.ylim(0, y_max * 1.1)
plt.gca().yaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f'{int(x / 1e6):,}M'))

for bar in barplot.patches:
    height = bar.get_height()
    plt.text(
        bar.get_x() + bar.get_width() / 2,
        height,
        f'{int(height):,}',
        ha='center',
        va='bottom',
        fontsize=8,
        color='black'
    )
plt.show()

agg_sales = sales.groupby('Store')['Weekly_Sales'].sum().reset_index()

sorted = agg_sales.sort_values(by='Weekly_Sales', ascending=True).head(3)

plt.figure(figsize=(12, 6))
barplot = sns.barplot(data=sorted, x='Store', y='Weekly_Sales',order = sorted['Store'], palette = "Set3")
plt.title('Weekly Sales by Store')
plt.xlabel('Store')
plt.ylabel('Weekly Sales')
plt.legend(title='Store')
plt.grid(False)



y_max = sorted['Weekly_Sales'].max()
plt.ylim(0, y_max * 1.1)
plt.gca().yaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f'{int(x / 1e6):,}M'))

for bar in barplot.patches:
    height = bar.get_height()
    plt.text(
        bar.get_x() + bar.get_width() / 2,
        height,
        f'{int(height):,}',
        ha='center',
        va='bottom',
        fontsize=8,
        color='black'
    )
plt.show()

store_20 = sales[sales['Store'] == 20]

# Create a scatter plot for Weekly_Sales vs. Temperature
plt.figure(figsize=(12, 6))
scatterplot = sns.scatterplot(data=store_20, x='Temperature', y='Weekly_Sales', palette="Set1")

plt.title('Weekly Sales vs. Temperature for Store 20', fontsize=16)
plt.xlabel('Temperature (Â°F)', fontsize=14)
plt.ylabel('Weekly Sales', fontsize=14)

# Formatting y-axis
y_max = store_20['Weekly_Sales'].max()
plt.ylim(0, y_max * 1.1)
plt.gca().yaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f'{int(x / 1e6):,}M'))

plt.grid(True, linestyle='--', alpha=0.7)
plt.show()

"""Sales by Year"""

agg_sales = sales.groupby('Year')['Weekly_Sales'].sum().reset_index()


sorted_sales = agg_sales.sort_values(by='Weekly_Sales', ascending=False)


plt.figure(figsize=(12, 6))
barplot = sns.barplot(data=sorted_sales, x='Year', y='Weekly_Sales', palette="Set1", order=sorted_sales['Year'])


plt.title('Total Weekly Sales by Year')
plt.xlabel('Year')
plt.ylabel('Total Weekly Sales')

y_max = sorted_sales['Weekly_Sales'].max()
plt.ylim(0, y_max * 1.1)
plt.gca().yaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f'{int(x / 1e6):,}M'))

for bar in barplot.patches:
    height = bar.get_height()
    plt.text(
        bar.get_x() + bar.get_width() / 2,
        height,
        f'{int(height):,}',
        ha='center',
        va='bottom',
        fontsize=10,
        color='black'
    )
plt.grid(False)
plt.show()

agg_sales = sales.groupby('Month')['Weekly_Sales'].mean().reset_index()


sorted_sales = agg_sales.sort_values(by='Weekly_Sales', ascending=False)


plt.figure(figsize=(12, 6))
barplot = sns.barplot(data=sorted_sales, x='Month', y='Weekly_Sales', palette="mako", order=sorted_sales['Month'])


plt.title('Average Weekly Sales by Month')
plt.xlabel('Month')
plt.ylabel('Average Weekly Sales')

y_max = sorted_sales['Weekly_Sales'].max()
plt.ylim(0, y_max * 1.1)
plt.gca().yaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f'{int(x / 1e6):,}M'))

for bar in barplot.patches:
    height = bar.get_height()
    plt.text(
        bar.get_x() + bar.get_width() / 2,
        height,
        f'{int(height):,}',
        ha='center',
        va='bottom',
        fontsize=7,
        color='black'
    )
plt.grid(False)
plt.show()

"""Sales by Quarter"""

agg_sales = sales.groupby('Quarter')['Weekly_Sales'].mean().reset_index()


sorted_sales = agg_sales.sort_values(by='Weekly_Sales', ascending=False)


plt.figure(figsize=(12, 6))
barplot = sns.barplot(data=sorted_sales, x='Quarter', y='Weekly_Sales', palette="rocket", order=sorted_sales['Quarter'])


plt.title('Average Weekly Sales by Quarter')
plt.xlabel('Quarter')
plt.ylabel('Average Weekly Sales')

y_max = sorted_sales['Weekly_Sales'].max()
plt.ylim(0, y_max * 1.1)
plt.gca().yaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f'{int(x / 1e6):,}M'))

for bar in barplot.patches:
    height = bar.get_height()
    plt.text(
        bar.get_x() + bar.get_width() / 2,
        height,
        f'{int(height):,}',
        ha='center',
        va='bottom',
        fontsize=7,
        color='black'
    )
plt.grid(False)
plt.show()

"""Sales by Holiday"""

holiday_sales = sales[sales['Holiday_Event'] != 'Not Holiday']


agg_sales = holiday_sales.groupby('Holiday_Event')['Weekly_Sales'].mean().reset_index()


sorted_sales = agg_sales.sort_values(by='Weekly_Sales', ascending=False)


plt.figure(figsize=(12, 6))
barplot = sns.barplot(data=sorted_sales, x='Holiday_Event', y='Weekly_Sales', palette="Set1", order=sorted_sales['Holiday_Event'])


plt.title('Average Weekly Sales by Holiday Events')
plt.xlabel('Holiday Events')
plt.ylabel('Average Weekly Sales')


y_max = sorted_sales['Weekly_Sales'].max()
plt.ylim(0, y_max * 1.1)
plt.gca().yaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f'{int(x / 1e6):,}M'))


for bar in barplot.patches:
    height = bar.get_height()
    plt.text(
        bar.get_x() + bar.get_width() / 2,
        height,
        f'{int(height):,}',
        ha='center',
        va='bottom',
        fontsize=7,
        color='black'
    )

plt.grid(False)
plt.show()

sales.dtypes





# from sklearn.preprocessing import StandardScaler

# numeric_cols = [
#   'Temperature',
#   'Fuel_Price',
#   'CPI',
#   'Unemployment']
# scaler = StandardScaler()

# # Fit and transform the numeric columns
# sales[numeric_cols] = scaler.fit_transform(sales[numeric_cols])

"""Encode"""

holiday_dummies = pd.get_dummies(sales['Holiday_Event'], drop_first=False)
holiday_dummies = holiday_dummies.astype(int)

# Drop the original 'Holiday_Event' column
sales = sales.drop('Holiday_Event', axis=1)

# Combine the dummy variables with the rest of the DataFrame
sales = pd.concat([sales, holiday_dummies], axis=1)

sales = sales.drop('Date', axis=1)
sales

sales.dtypes

predictors = ['Store', 'Holiday_Flag', 'Temperature', 'Fuel_Price', 'CPI', 'Unemployment',
              'Quarter', 'Year', 'Month', 'Day', 'Week_of_Year', 'Christmas', 'Labor Day',
              'Not Holiday', 'Super Bowl', 'Thanksgiving']


X = sales[predictors]

X

y = sales['Weekly_Sales']

import numpy as np
import random

np.random.seed(0)
random.seed(0)

"""Split data"""

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,
                                                      random_state=0)

"""Decision Tree Regressor for continuous variable"""

from sklearn.tree import DecisionTreeRegressor
tree = DecisionTreeRegressor(random_state=0)

from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import numpy as np
tree.fit(X_train, y_train)
y_pred = tree.predict(X_test)


mse = mean_squared_error(y_test, y_pred)
rmse = mse**0.5
r2 = r2_score(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)


# print(f"Mean Squared Error (MSE): {mse:.3f}")
print(f"Root Mean Squared Error (RMSE): {rmse:.3f}")
print(f"R-squared: {r2:.3f}")
print(f"Mean Absolute Error (MAE): {mae:.3f}")

pd.set_option('display.max_rows', None)  # Show all rows
pd.set_option('display.max_columns', None)  # Show all columns
pd.set_option('display.max_colwidth', None)  # Show full content of each column

importance = pd.DataFrame(tree_pruned.feature_importances_, index = X.columns, columns = ["Importance"])
importance.sort_values(by = "Importance", ascending = False)

from sklearn.tree import plot_tree
fig = plt.figure(figsize=(60,20))  # Adjust size for better visibility
plot_tree(tree_pruned,
          feature_names=X_train.columns,  # Use X_train.columns if X is your feature matrix
          filled=True,
          rounded=True,
          fontsize=12)  # Adjust fontsize if needed

plt.show()

"""GRID SEARCH FOR DECISION TREE"""

tree = DecisionTreeRegressor(random_state=0)
tree.get_params()

from sklearn.model_selection import GridSearchCV


param_grid = {
    'max_depth': [10, 20, 30, 40, 50, None],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'max_features': [None, 'sqrt','log2']
}


# grid_search = GridSearchCV(estimator=tree, param_grid=param_grid, cv=5,
#                            scoring='neg_mean_squared_error', return_train_score=True)


grid_search = GridSearchCV(estimator=tree, param_grid=param_grid,
                           cv=5, n_jobs=-1, verbose=2, scoring='neg_mean_squared_error')

grid_search.fit(X_train, y_train)


best_params = grid_search.best_params_

best_dtree_reg = grid_search.best_estimator_
y_pruned_pred = best_dtree_reg.predict(X_test)
mae = mean_absolute_error(y_test, y_pruned_pred)
mse = mean_squared_error(y_test, y_pruned_pred)
rmse = mse ** 0.5
r2 = r2_score(y_test, y_pruned_pred)


print(f"Best parameters: {best_params}")
# print(f"Mean Squared Error (MSE): {mse:.3f}")
print(f"Root Mean Squared Error (RMSE): {rmse:.3f}")
print(f"R-squared: {r2:.3f}")

results_df = pd.DataFrame({'Actual Sales': y_test, 'Predicted Sales': y_pruned_pred})


print(results_df.head(10).to_string(index=False))

"""RANDOM FOREST

"""

from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error

# Initialize and fit the model
forest = RandomForestRegressor(random_state = 0)
forest.fit(X_train, y_train)

# Make predictions
y_rf_pred = forest.predict(X_test)

mse = mean_squared_error(y_test, y_rf_pred)
rmse = mse**0.5
r2 = r2_score(y_test, y_rf_pred)
mae = mean_absolute_error(y_test, y_rf_pred)


# print(f"Random Forest Mean Squared Error (MSE): {mse:.3f}")
print(f"Random Forest Mean Squared Error (RMSE): {rmse:.3f}")
print(f"Random Forest R-squared: {r2:.3f}")
print(f"Random Forest Mean Absolute Error (MAE): {mae:.3f}")

importances = forest.feature_importances_

df = pd.DataFrame({'Feature': X.columns, 'Importance': importances})
df = df.sort_values('Importance', ascending = False)
df

"""GRID SEARCH FOR RANDOM FOREST"""

# Fine-Tune model using GridSearch
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import make_scorer, mean_absolute_error

param_grid = [
    {'n_estimators': [3, 10, 30, 45, 60], 'max_features': [2, 4, 6, 8]}
]
scoring = make_scorer(mean_absolute_error, greater_is_better=False)

forest_reg = RandomForestRegressor(random_state =0)
grid_search = GridSearchCV(forest_reg, param_grid, cv = 5,
                           scoring = scoring,
                           return_train_score = True)

grid_search.fit(X_train, y_train)

# Best parameters
print("Best parameters found: ", grid_search.best_params_)



# Get the best model
best_forest_reg = grid_search.best_estimator_

# Make predictions with the best model
y_best_pred = best_forest_reg.predict(X_test)



mse_best = mean_squared_error(y_test, y_best_pred)
rmse_best = mse_best**0.5
r2_best = r2_score(y_test, y_best_pred)
mae_best = mean_absolute_error(y_test, y_best_pred)


# print(f"Best Random Forest Mean Squared Error (MSE): {mse_best:.3f}")
print(f"Best Random Forest Root Mean Squared Error (RMSE): {rmse_best:.3f}")
print(f"Best Random Forest R-squared: {r2_best:.3f}")
print(f"Best Random Forest Mean Absolute Error: {mae_best:.3f}")

results_df = pd.DataFrame({'Actual Sales': y_test, 'Predicted Sales': y_best_pred})

# Display the DataFrame

print(results_df.head(10).to_string(index=False))
